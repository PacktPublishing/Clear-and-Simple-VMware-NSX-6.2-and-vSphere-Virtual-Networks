WEBVTT

00:00.540 --> 00:09.000
So now let's say that V.M. one wants to ping V.M. till Let's walk through what happens.

00:09.000 --> 00:17.040
So here we see the ping that's being generated by V.M. one in orange the far left we see the destination

00:17.070 --> 00:24.400
IP is 192 out 168 not 1 not 11 and VM one has a guest operating system.

00:24.530 --> 00:31.060
And let's just assume that within that guest operating system the ARP table already has an entry.

00:31.220 --> 00:40.280
So the ARP table a VM one has an entry that maps this IP address to this MAC address so we don't need

00:40.280 --> 00:46.010
to do on our request right now in a couple of slides I'll walk you through what happens if we do need

00:46.010 --> 00:52.370
to do in our request but for the sake of this particular example let's say that VM one already has that

00:52.560 --> 00:55.250
table entry.

00:55.260 --> 00:59.250
OK so VM one generates this ping destined for VM to

01:02.460 --> 01:09.720
now when that traffic hits the tab the tab is going to do on a Mac table look up to determine which

01:09.990 --> 01:15.320
tab is Mac to associated with.

01:15.360 --> 01:21.810
And in this case Mac 2 was associated with the tap on this second host be tapped to

01:29.940 --> 01:34.570
so Mac to is associate with 10 not one not one of 11.

01:34.570 --> 01:35.580
That's the Wii.

01:35.740 --> 01:43.420
So what we tap one will do is it will now take that original frame it will encapsulate it within a new

01:43.420 --> 01:51.870
set of our headers and it will send that frame towards V tap to.

01:52.080 --> 02:00.120
And when we have to receive it it'll be the job of the top to to d capsulized that frame and remove

02:00.120 --> 02:02.490
all of those headers that were created.

02:02.490 --> 02:09.540
Those outer Hadash and past the frame along to a logical switch V and five thousand one so that it can

02:09.540 --> 02:14.610
eventually reach the M2.

02:14.610 --> 02:26.620
Now how does this sending VTM determine how to get that frame from the tap one to tap to the sending

02:26.620 --> 02:32.410
the tap new the IP address destination of that V tap.

02:32.500 --> 02:34.870
But it's going to need to know the MAC address as well.

02:35.050 --> 02:41.320
And because what we have here is Alair to network and it needs to know which MAC address for this frame.

02:41.470 --> 02:43.760
That's the purpose of the V tap table.

02:43.860 --> 02:51.090
The tap table contains IP to MAC address mappings for all of Arvie taps.

02:51.090 --> 02:58.710
Now let's shift gears a little bit and think about a different situation in which VM one wants to ping

02:58.950 --> 03:01.970
a virtual machine called VM five.

03:02.020 --> 03:09.520
And in this case let's assume that VM one does not know the destination MAC of the amphi.

03:09.740 --> 03:15.380
Or maybe it knows the IP address but it doesn't know the destination MAC.

03:15.400 --> 03:21.790
So what happens in this scenario are we see both of these SMS are on the same network.

03:22.090 --> 03:24.900
We can see that their IP addresses are in the same range.

03:24.970 --> 03:29.650
So there's no default gateway or routing involved here.

03:29.780 --> 03:36.470
So if VM one wants to discover the MAC address of VM five it's going to have to issue an op request

03:38.380 --> 03:46.630
and ARP request is a layer to broadcast so broadcasts are not really desirable.

03:46.670 --> 03:46.920
Right.

03:46.940 --> 03:51.610
We've got all of these other virtual machines that are part of this network as well.

03:52.610 --> 03:55.510
And they're not involved in this communication.

03:55.850 --> 04:02.240
But when VM one tries to discover the MAC address of VM five it's going to issue a broadcast and that

04:02.240 --> 04:04.910
broadcast is going to hit the physical switch.

04:06.080 --> 04:14.210
And a copy of it is going to be transmitted to every single virtual machine regardless of which one

04:14.210 --> 04:20.270
is actually the true destination until one of these victims actually responds says yes I see that's

04:20.270 --> 04:21.350
my MAC address.

04:21.480 --> 04:23.080
Here is my IP address.

04:23.090 --> 04:25.300
That's how an op request works.

04:26.200 --> 04:34.630
So this is a broadcast and broadcasts are not desirable because it creates a lot of traffic so ideally

04:34.870 --> 04:41.810
we'd like to suppress as many our requests as we possibly can.

04:42.030 --> 04:47.470
And that's where the ARP table of the NSX controller can help us.

04:47.470 --> 04:49.590
So here we see another example.

04:49.750 --> 04:57.110
VM one wants to ping VM to and we can see in our little orange box on the left that VM one knows the

04:57.110 --> 05:06.140
destination IP but it does not know the destination MAC and therefore it must issue our request to discover

05:06.140 --> 05:09.720
that MAC address.

05:09.770 --> 05:10.580
So here goes.

05:10.580 --> 05:15.490
V.M. one issuing this broadcast this ARP request.

05:15.660 --> 05:23.580
But in this case the V tap is going to see that broadcast ARP requests and rather than broadcasting

05:23.580 --> 05:29.640
it to everything connected to this logical switch with the Wii tap will do is it will intercept the

05:29.790 --> 05:37.410
request and prior to broadcasting it it'll queery the NSX controller to see if the NSX controller has

05:37.410 --> 05:41.500
an ARP table entry to match that IP address.

05:42.240 --> 05:50.380
And if it does the NSX controller will fulfill that request without a broadcast ever occurring.

05:51.430 --> 05:55.340
So now that the ARP request has been fulfilled.

05:55.630 --> 06:03.220
Now virtual machine one is able to populate its own local ARP table in the guest operating system and

06:03.220 --> 06:13.980
for all future communications it'll be aware of the IP to MAC address mapping of VM to.

06:13.990 --> 06:18.240
So now we've talked about some of the things that the NSX controller does.

06:18.250 --> 06:23.950
Let's talk about how the NSX controller cluster is deployed will use NSX manager.

06:23.990 --> 06:27.150
NSX manager always has to be set up first.

06:27.280 --> 06:33.770
So when we're creating an NSX deployment we'll get ex-manager up and running.

06:33.860 --> 06:39.670
Integrate it with the center will register with a V Center server and will then use the VSE for web

06:39.670 --> 06:49.380
client to deploy the NSX controller cluster nodes and NSX Mandar has the required over Yeff template

06:49.770 --> 06:58.800
which we're going to use to deploy these virtual appliances from every NSX controller cluster should

06:58.800 --> 07:00.530
have three notes.

07:00.540 --> 07:07.350
So there's going to be three virtual appliances that are part of our NSX controller cluster.

07:07.560 --> 07:08.740
You don't want more.

07:08.820 --> 07:15.860
You don't want less This is a universal standard that V.M. war has identified as the best practice for

07:15.870 --> 07:24.450
NSX controller Klosters they should always have three notes and part of the NSX controller costs or

07:24.450 --> 07:26.830
is this user world agent.

07:26.970 --> 07:33.450
Things like are are up and Mac and V-Tech tables are all going to be updated by this user world engine

07:33.480 --> 07:41.820
that runs on the ESX hosts and when we do host preparation one of the things that the NSX manager is

07:41.820 --> 07:48.370
going to do is it's actually going to enable the excellent capabilities it's going to establish that

07:48.370 --> 07:57.630
the taps on the ESX hosts and as our virtual machines are connected to logical switches the user world

07:57.660 --> 08:02.680
agent tracks changes to the Mac ARP and V-Tech tables.

08:03.430 --> 08:09.610
And it uses those reports that we looked at in the earlier slides to keep that NSX controller cluster

08:09.610 --> 08:11.790
up to date.

08:11.820 --> 08:19.440
Now all communications between the NSX controller cluster and the ESX hosts are encrypted.

08:19.570 --> 08:22.650
It runs as a demon on the host called CPA.

08:22.900 --> 08:24.240
That's my user agent

08:27.050 --> 08:33.560
and the user agent is not used to manage the distributed firewall so the user road agent is used for

08:33.560 --> 08:37.640
communications between the host and the NSX controller.

08:37.640 --> 08:47.030
Kloster the distributed firewall is managed by NSX manager and it uses a different daemon called vs

08:47.120 --> 08:54.110
AF W.D. And so just that's an important thing to keep straight for the VCP if you're planning on taking

08:54.110 --> 09:02.270
the VCP exam the NSX manager directly manages the distributed firewall and the user wrold agent is not

09:02.270 --> 09:06.850
used for that.

09:06.910 --> 09:13.850
All right so in review the NSX controllers part of the control plane no actual virtual machine traffic

09:13.940 --> 09:16.100
flows through the NSX controller.

09:17.110 --> 09:22.430
We wanna deploy three NSX controller nodes as part of our cluster.

09:22.450 --> 09:30.150
That's the only supported configuration will have one and OSX controller cluster for each.

09:30.180 --> 09:37.150
And OS X manager instance in our NSX controller closter and we'll see a little bit more of this as we

09:37.150 --> 09:38.800
go through the rest of the videos.

09:39.010 --> 09:46.040
But one of our NSX controller cluster nodes will be established as a master for each role.

09:46.210 --> 09:52.960
And like I said we'll take a closer look at that as we move throughout the video in upcoming videos.

09:52.960 --> 10:00.120
We'll also look at a mechanism called slicing that's used to distribute workload across those three

10:00.130 --> 10:01.770
NSX controller nodes.

10:01.780 --> 10:03.240
So stay tuned for that.
